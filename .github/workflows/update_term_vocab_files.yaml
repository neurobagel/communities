name: Update standardized term vocab files for community configs

on:
  schedule:
    # Run once a week on Monday at 8 AM EST in winter, 9 AM EDT in summer
    - cron: '0 13 * * 1'
  workflow_dispatch:

jobs:
  define-matrix:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    outputs:
      community_names: ${{ steps.get-config-dirs.outputs.community_names }}
    steps:
      - name: Checkout
        uses: actions/checkout@v5

      - name: Get community config directory names
        id: get-config-dirs
        # NOTE: We only store the directory basename since we need a variable without slashes for a unique artifact name later on
        run: |
          community_names=$(find configs -mindepth 1 -maxdepth 1 -type d -exec basename {} \; \
            | grep -v "Neurobagel" \
            | jq -R . | jq -s .)
          echo "community_names=$community_names" >> "$GITHUB_OUTPUT"

  update-terms:
    needs: define-matrix
    runs-on: ubuntu-latest
    permissions:
      contents: read
    strategy:
      fail-fast: false
      matrix:
        community_name: ${{ fromJson(needs.define-matrix.outputs.community_names) }}

    steps:
      - name: Checkout
        uses: actions/checkout@v5

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run script
        env:
          COMMUNITIES_GOOGLE_API_KEY: ${{ secrets.COMMUNITIES_GOOGLE_API_KEY }}
        run: python code/create_term_vocab_from_gsheet.py "configs/${{ matrix.community_name }}"

      # NOTE: We upload the entire directory to avoid needing to know/hardcode the name of the specific vocab file
      # (which is technically arbitrary) and to allow for future expansion to files for multiple standardized variables
      # (which the script already supports)
      - name: Upload community config directory as artifact
        uses: actions/upload-artifact@v4
        with:
          name: community_name_${{ matrix.community_name }}
          path: configs/${{ matrix.community_name }}

  # NOTE: We commit once after all vocab files have been updated
  # to avoid race conditions with multiple concurrent pushes
  commit-files:
    needs: update-terms
    if: ${{ always() }}
    permissions:
      contents: write
    runs-on: ubuntu-latest

    steps:
      - name: Generate a Neurobagel Bot token
        id: generate-token
        uses: actions/create-github-app-token@v2
        with:
          app-id: ${{ vars.NB_BOT_ID }}
          private-key: ${{ secrets.NB_BOT_KEY }}

      - name: Checkout
        uses: actions/checkout@v5
        with:
          token: ${{ steps.generate-token.outputs.token }}

      - name: Download all artifacts
        uses: actions/download-artifact@v5
        with:
          path: .

      - name: Get Neurobagel Bot App User ID
        id: get-user-id
        run: echo "user-id=$(gh api "/users/${{ steps.generate-token.outputs.app-slug }}[bot]" --jq .id)" >> "$GITHUB_OUTPUT"
        env:
          GH_TOKEN: ${{ steps.generate-token.outputs.token }}

      - name: Configure git for Neurobagel Bot user
        run: |
          git config --global user.name '${{ steps.generate-token.outputs.app-slug }}[bot]'
          git config --global user.email '${{ steps.get-user-id.outputs.user-id }}+${{ steps.generate-token.outputs.app-slug }}[bot]@users.noreply.github.com'

      - name: Commit and push if any community config files have changed
        run: |
          if ! git diff --quiet configs; then
            git add configs
            git commit -m "[bot] Update community standardized term vocab files from Google Sheets"
            git push origin main
          fi
